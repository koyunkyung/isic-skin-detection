{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CYim1ptllD1c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from src.data.preprocessing import preprocess_metadata, get_transform\n",
        "from src.data.dataset import SkinLesionDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 경로\n",
        "train_meta_path = \"data/raw/train-metadata.csv\"\n",
        "train_img_hdf5 = \"data/raw/train-image.hdf5\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 메타데이터 전처리\n",
        "df_raw = pd.read_csv(train_meta_path)\n",
        "df_processed, scaler = preprocess_metadata(df_raw)\n",
        "\n",
        "# train/validation split\n",
        "train_df, val_df = train_test_split(\n",
        "    df_processed, test_size=0.2, stratify=df_processed['target'], random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = SkinLesionDataset(\n",
        "    df=train_df,\n",
        "    hdf5_path=train_img_hdf5,\n",
        "    transforms=get_transform(phase=\"train\"),\n",
        "    use_metadata=False\n",
        ")\n",
        "val_dataset = SkinLesionDataset(\n",
        "    df=val_df,\n",
        "    hdf5_path=train_img_hdf5,\n",
        "    transforms=get_transform(phase=\"val\"),\n",
        "    use_metadata=False\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "lVtlKTIll32H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b906908-a8cf-465d-e4e1-c383e590e68b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2-3446282248.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_raw = pd.read_csv(train_meta_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from src.models.cnn import SimpleCNN\n",
        "\n",
        "# 장치 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델 초기화\n",
        "model = SimpleCNN(pretrained=True).to(device)\n",
        "# 손실함수 및 옵티마이저\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbOkPM6NmcnY",
        "outputId": "8de032dc-6e76-4769-cfc1-92fd3f3216de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 135MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")"
      ],
      "metadata": {
        "id": "Rt43Z-4ymdRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f25a692-d52d-4310-f1b2-d5b78bd8ddb1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Train Loss: 0.0084\n",
            "Epoch [2/5], Train Loss: 0.0075\n",
            "Epoch [3/5], Train Loss: 0.0073\n",
            "Epoch [4/5], Train Loss: 0.0070\n",
            "Epoch [5/5], Train Loss: 0.0069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증\n",
        "model.eval()\n",
        "val_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "avg_val_loss = val_loss / len(val_loader)\n",
        "print(f\"Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "K3MvRrvTmyhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320fb01f-e4c0-43be-b987-8d82b13b020f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Val Loss: 0.0068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"outputs/simple_cnn.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"모델이 저장되었습니다: {model_path}\")"
      ],
      "metadata": {
        "id": "PiwC6t3lntt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4957c49e-9d20-44c0-9a01-67bdee556e71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델이 저장되었습니다: outputs/simple_cnn.pth\n"
          ]
        }
      ]
    }
  ]
}